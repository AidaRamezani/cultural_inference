{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8cbf1962",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9611f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "wave = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90931693",
   "metadata": {},
   "outputs": [],
   "source": [
    "wvs_mcm = pd.read_csv(f'../data/wvs_w{wave}_mcm.csv')\n",
    "wvs_gpt3 = pd.read_csv('../data/wvs_w7_gpt3.csv')\n",
    "wvs_gpt2 = pd.read_csv('../data/wvs_w7_gpt2_token_pairs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9080005",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2_models = ['gpt2', 'gpt2-medium','gpt2-large']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42f2c89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "wvs_gpt2_universal = wvs_gpt2.loc[wvs_gpt2.country == 'universal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "afe6ef17",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_types = ['random', 'country_based','topic based','removed topics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10252e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_eval_pairs = pickle.load(open('../data/wvs_eval_pairs.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a11f17c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "wvs_gpt2 = pd.read_csv(f'../data/wvs_w7_gpt2_token_pairs.csv') #PRE-TRAINED MODEL\n",
    "wvs_gpt2_cultural = wvs_gpt2.loc[wvs_gpt2['country'] != 'universal']\n",
    "wvs_gpt2_cultural = wvs_gpt2_cultural.loc[~pd.isna(wvs_gpt2_cultural['wvs_score'])] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b10ec2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "pew_topics = {'use contraceptives':'using contraceptives',\n",
    "           'get a divorce':'getting a divorce', \n",
    "            'have an abortion': 'having an abortion',\n",
    "            'be homosexual': 'homosexuality', \n",
    "           'drink alcohol': 'drinking alcohol',\n",
    "           'have an extramarital affair': 'married people having an affair' ,\n",
    "             'gamble': 'gambling',\n",
    "       'have sex between unmarried adults':'sex between unmarried adults'\n",
    "                         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a985819f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def included_function(pairs,data):\n",
    "    def func(row):\n",
    "        \n",
    "        return (row['country'], row['topic']) in pairs\n",
    "    return func"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb018df4",
   "metadata": {},
   "source": [
    "## Evaluating on WVS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6bbd1bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_rows = []\n",
    "for test_type in test_types:\n",
    "    \n",
    "    eval_pairs = all_eval_pairs[test_type]\n",
    "    \n",
    "    wvs_gpt2_cultural_copy = wvs_gpt2_cultural.copy()\n",
    "    wvs_gpt2_cultural_copy['included'] = wvs_gpt2_cultural_copy.apply(included_function(eval_pairs, 'wvs'), axis = 1)\n",
    "    wvs_gpt2_cultural_test = wvs_gpt2_cultural_copy.loc[wvs_gpt2_cultural_copy.included == True]\n",
    "    \n",
    "    \n",
    "    r, p = scipy.stats.pearsonr(wvs_gpt2_cultural_test['wvs_score'], wvs_gpt2_cultural_test['log prob difference'])\n",
    "    row = {'model': 'gpt2', 'test type': test_type, 'r' : r, 'p': p ,'n': len(wvs_gpt2_cultural_test)}\n",
    "    list_rows.append(row)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0fb035fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>test type</th>\n",
       "      <th>r</th>\n",
       "      <th>p</th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>random</td>\n",
       "      <td>0.271075</td>\n",
       "      <td>0.000325</td>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>country_based</td>\n",
       "      <td>0.225309</td>\n",
       "      <td>0.005058</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>topic based</td>\n",
       "      <td>0.285583</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>removed topics</td>\n",
       "      <td>0.273920</td>\n",
       "      <td>0.000212</td>\n",
       "      <td>212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model       test type         r         p    n\n",
       "0  gpt2          random  0.271075  0.000325  206\n",
       "1  gpt2   country_based  0.225309  0.005058  202\n",
       "2  gpt2     topic based  0.285583  0.000081  216\n",
       "3  gpt2  removed topics  0.273920  0.000212  212"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(list_rows)\n",
    "df['p'] = multipletests(df['p'], method = 'bonferroni', alpha = 0.5)[1]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8dce8f",
   "metadata": {},
   "source": [
    "## Evaluating on PEW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c295ded2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pew_mcm = pd.read_csv(f'../data/pew_mcm.csv')\n",
    "pew_gpt3 = pd.read_csv('../data/pew_gpt3.csv')\n",
    "gpt2_topic_mapping = {'use contraceptives': 'using contraceptices',\n",
    "                     'get a divorce': 'getting a divorce',\n",
    "                     'have an abortion': 'having an abortion',\n",
    "                     'be homosexual': 'Homosexuality',\n",
    "                     'drink alcohol':'drinking alcohol',\n",
    "                     'have an extramarital affair':'married people having an affair',\n",
    "                     'gamble' :'gambling',\n",
    "                      'have sex between unmarried adults': 'sex between unmarried adults'\n",
    "                     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "53bfb7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_rows = []\n",
    "all_eval_pairs = pickle.load(open('../data/pew_eval_pairs.p','rb'))\n",
    "pew_gpt2 = pd.read_csv(f'../data/pew_gpt2_token_pairs.csv')\n",
    "pew_gpt2['topic'] = pew_gpt2['topic'].apply(lambda t : gpt2_topic_mapping[t])\n",
    "pew_gpt2_cultural = pew_gpt2.loc[pew_gpt2['country'] != 'universal']\n",
    "for test_type in test_types:\n",
    "    \n",
    "    eval_pairs = all_eval_pairs[test_type]\n",
    "    pew_gpt2_cultural_copy = pew_gpt2_cultural.copy()\n",
    "    pew_gpt2_cultural_copy['included'] = pew_gpt2_cultural_copy.apply(included_function(eval_pairs, 'pew2'), axis = 1)\n",
    "    pew_gpt2_cultural_test = pew_gpt2_cultural_copy.loc[pew_gpt2_cultural_copy.included == True]\n",
    "   \n",
    "    r, p = scipy.stats.pearsonr(pew_gpt2_cultural_test['pew_score'], pew_gpt2_cultural_test['log prob difference'])\n",
    "    row = {'model': 'gpt2', 'test type': test_type, 'r' : r, 'p': p ,'n': len(pew_gpt2_cultural_test)}\n",
    "    list_rows.append(row)\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "907ded4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>test type</th>\n",
       "      <th>r</th>\n",
       "      <th>p</th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>random</td>\n",
       "      <td>0.203729</td>\n",
       "      <td>0.760286</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>country_based</td>\n",
       "      <td>0.054602</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>topic based</td>\n",
       "      <td>-0.145769</td>\n",
       "      <td>0.811463</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>removed topics</td>\n",
       "      <td>-0.108845</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model       test type         r         p   n\n",
       "0  gpt2          random  0.203729  0.760286  43\n",
       "1  gpt2   country_based  0.054602  1.000000  48\n",
       "2  gpt2     topic based -0.145769  0.811463  78\n",
       "3  gpt2  removed topics -0.108845  1.000000  78"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(list_rows)\n",
    "df['p'] = multipletests(df['p'], method = 'bonferroni', alpha = 0.5)[1]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79004c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
